---
title: "Case Study in Addressing Missing Values: Pima Indians Diabetes Data" 
author: "Ben Fauber"
date: "November 14, 2016"
output: html_document
---

### Diabetes

<A HREF="https://en.wikipedia.org/wiki/Diabetes_mellitus">Diabetes mellitus</A> is a metabolic disease that impacts the body's ability to normalize blood sugar levels.  Diabetes is due to either the pancreas not producing enough insulin or the cells of the body not responding properly to the insulin produced.
 If left untreated, diabetes can cause many complications such as heart disease, stroke, chronic kidney failure, foot ulcers, damage to the eyes, or death.

Diabetes is characterized by recurrent or persistent high blood sugar.  It is typically diagnosed by demonstrating plasma glucose â‰¥ 11.1 mmol/L (200 mg/dL) two hours after a 75 g oral glucose load as in a glucose tolerance test.


### Pima Indians Diabetes Data Set

The Pima Indians Diabetes data set is a publicly available data set from the University of California at Irvine Machine Learning database: https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes

Several college upper-level statistics courses make use of this data set to teach modeling approaches, and the data set also is a topic of frequent discussion on the data science website <A HREF="https://www.kaggle.com/uciml/pima-indians-diabetes-database">Kaggle</A>.  

Rather than borrowing from the existing code and kernels on Kaggle, I chose to build my R script from scratch, showcasing my approach in addressing with the missing data values (>50% incomplete rows) and constructing robust models.


##### Data Set Information

Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.

Attribute Information:

1. Number of times pregnant
2. Plasma glucose concentration at 2 hours in an oral glucose tolerance test (mM)
3. Diastolic blood pressure (mm Hg)
4. Triceps skin fold thickness (mm)
5. 2-Hour serum insulin (mu U/mL)
6. Body mass index (weight in kg/(height in m)^2)
7. Diabetes pedigree function
8. Age (years)
9. Class variable (0 or 1), 0=negative for diabetes, 1=positive


### Goal

Identify a robust and general data model to accurately classify current (and potential patients) into bins of negative or positive for diabetes (Class variable, column 9 in data set) based on known risk factors (other data in the data set).

Optimize and select an appropriate model using training data.  Use cross-validation to avoid overfitting the training data. Validate the model using hold-out data and identify the optimal model and parameters.


### Loading and Visualizing the Data

```{r warning=FALSE}
library(C50)
library(caret)
library(e1071)
library(ggplot2)
library(kernlab)
library(mice)
library(plyr)
library(randomForest)
library(VIM)

pima <- read.table("~/Desktop/PimaIndianDiabetesData/MAIN_pima-indians-diabetes.data", sep = ",", na.strings="0.0", strip.white=TRUE, fill=TRUE)
```

#### Assign column headers

```{r, warning=FALSE}
names(pima) <- c("timesPreg", "glucConc", "bloodPres", "skinThick", "serumInsul", "bmi", "pedigreeFunc", "age", "classVar")
```

#### Understanding the data using summary stats

```{r, warning=FALSE}
str(pima)

summary(pima)
```

bmi has 11 NA's

Strong skew on serumInsul due to high-end outliers

```{r, warning=FALSE}
table(pima$timesPreg)
```

timesPreg peaks around 1 time, max= 17 times (n=1)

```{r, warning=FALSE}
table(pima$classVar)
```

35% are Class 1

```{r, warning=FALSE}
pimaSub1 <- subset(pima, (
	pima$glucConc > 0 & pima$bloodPres > 0 &
	pima$skinThick > 0 & pima$serumInsul > 0 &
	pima$bmi > 0 & pima$pedigreeFunc > 0 &
	pima$age > 0))
```

n=392 (51%)


### Using CARET to examine co-linearity in pimaSub1 data

#### convert data.frame to numeric format for analysis 

```{r, warning=FALSE}
for(i in c(1:ncol(pimaSub1))) 
{
    pimaSub1[,i] <- as.numeric(as.character(pimaSub1[,i]))
}

pimaSub1.cor <- round(cor(pimaSub1), 2)

print(pimaSub1.cor)
```

Strongest correlation: r = 0.68, age to timesPreg

Also: r = 0.66, bmi to skinThick

Strongest meaningful correlation (r = 0.58), glucConc to serumInsul

GlucConc has the strongest correation (r = 0.52) to classVar

Age is #2 with r = 0.35 to classVar

#### Revisit the strongest correlations with plots.

Density distribution plots, segmented by classVar

```{r echo=FALSE}
pima$classVar <- factor(pima$classVar)

ggplot(data=pima, aes(x=timesPreg, fill=pima$classVar)) + 
	geom_density(alpha=0.4) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Number of Times Pregnant")

ggplot(data=pima, aes(x=glucConc, fill=classVar)) + 
	geom_density(alpha=0.4) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Plasma Glucose Concentration, 2 h p.o. Gluc. Tol. Test (mM)")

ggplot(data=pima, aes(x=bloodPres, fill=classVar)) + 
	geom_density(alpha=0.4) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Diastolic blood pressure (mm Hg)")

ggplot(data=pima, aes(x=skinThick, fill=classVar)) + 
	geom_density(alpha=0.4) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Triceps skin fold thickness (mm)")
	
ggplot(data=pima, aes(x=serumInsul, fill=classVar)) + 
	geom_density(alpha=0.4) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="2 h serum insulin (mu U/mL)")

ggplot(data=pima, aes(x=bmi, fill=classVar)) + 
	geom_density(alpha=0.4) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Body mass index (weight in kg/(height in m)^2)")

ggplot(data=pima, aes(x=pedigreeFunc, fill=classVar)) + 
	geom_density(alpha=0.4) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Diabetes pedigree function")
	
ggplot(data=pima, aes(x=age, fill=classVar)) + 
	geom_density(alpha=0.4) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Age (years)")	
```

Density plot of classVar

```{r echo=FALSE}	
ggplot(pima) + 
	geom_density(aes(x=classVar), 
	color="blue", 
	fill="blue",
	alpha=0.2) +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Class variable (0 or 1)")
```

Histogram of timesPreg

```{r echo=FALSE}
ggplot(pima) + 
	geom_bar(aes(x=timesPreg), 
	color="blue", 
	fill="blue") +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Number of Times Pregnant")
```

Futher examining the cor identified in the above section, using the pimaSub1 data

```{r echo=FALSE}
ggplot(pimaSub1, aes(x=age, y=timesPreg)) + 
	geom_point(color="blue") + 
	geom_smooth() +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Age (years)", y="Number of Times Pregnant")

ggplot(pimaSub1, aes(x=skinThick, y=bmi)) + 
	geom_point(color="blue") + 
	geom_smooth() + 
	stat_smooth(method="lm", color="red") +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Triceps skin fold thickness (mm)", 
	y="Body mass index (weight in kg/(height in m)^2)")
# nearly linear relationship, added stat_smooth line
			
ggplot(pimaSub1, aes(x=glucConc, y=serumInsul)) + 
	geom_point(color="blue") + 
	geom_smooth() +
	stat_smooth(method="lm", color="red") +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Plasma Glucose Concentration, 2 h p.o. Gluc. Tol. Test (mM)",
	y="2 h serum insulin (mu U/mL)")
# nearly linear relationship, added stat_smooth line

ggplot(pimaSub1, aes(x=glucConc, y=classVar)) + 
	geom_point(color="blue", position=position_jitter(w=0.1, h=0.1)) + 
	geom_smooth() +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Plasma Glucose Concentration, 2 h p.o. Gluc. Tol. Test (mM)",
	y="Class variable (0 or 1)")
```

Visualizing the relationship of other pimaSub1 variables to classVar

```{r echo=FALSE}
ggplot(pimaSub1, aes(x=timesPreg, y=classVar)) + 
	geom_point(color="blue", position=position_jitter(w=0.1, h=0.1)) + 
	geom_smooth() +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Number of Times Pregnant",
	y="Class variable (0 or 1)")

ggplot(pimaSub1, aes(x=bmi, y=classVar)) + 
	geom_point(color="blue", position=position_jitter(w=0.1, h=0.1)) + 
	geom_smooth() +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Body mass index (weight in kg/(height in m)^2)",
	y="Class variable (0 or 1)")

ggplot(pimaSub1, aes(x=age, y=classVar)) + 
	geom_point(color="blue", position=position_jitter(w=0.1, h=0.1)) + 
	geom_smooth() +
	labs(title="Pima Indians Diabetes Data") +
	labs(x="Age (years)",
	y="Class variable (0 or 1)")
```

### Cleaning the Data

```{r warning=FALSE}
summary(pima)
```

All values are finite, some NA values present in bmi

Omit all unique identifiers in model data:
None found in data, pass

```{r warning=FALSE}
p <- pima
```

Notes with raw data indicated that all but timesPreg and ClassVar cols zero values == NA

Addressing the NA and zero values in all but timesPreg and classVar cols

```{r warning=FALSE}
p$glucConc[p$glucConc == 0] <- NA
p$bloodPres[p$bloodPres == 0] <- NA
p$skinThick[p$skinThick == 0] <- NA
p$serumInsul[p$serumInsul == 0] <- NA
p$bmi[p$bmi == 0] <- NA
p$pedigreeFunc[p$pedigreeFunc == 0] <- NA
p$age[p$age == 0] <- NA
```

List the rows that do not have missing values

```{r warning=FALSE}
pComp <- p[complete.cases(p), ]

nrow(pComp)
```

392 complete case rows (out of 768, 51%)

List the rows that have one or more missing values:

```{r warning=FALSE}
pInc <- p[!complete.cases(p), ]

nrow(pInc)
```

376 incomplete case rows (out of 768, 49%)

Significant percentage of rows are missing at least one value, thus cannot omit.

Rows that contain NA values in analysis without losing ~50% of data

#### Using MICE to understand missing data patterns

```{r warning=FALSE}
md.pattern(p)
```

192 rows have all data except serumInsul and skinThick

140 rows have all data except serumInsul

26 rows have all data except serumInsul, skinThick, and bloodPres

7 rows have all data except serumInsul, skinThick, bloodPres, and bmi

4 rows have all data except glucConc and serumInsul

7 rows have all data exept a mixture of 1-3 columns

no NA's present for timesPreg, pedigreeFunc, age, and classVar

Thus, addressing the serumInsul NA values can address most of the missing data, followed by skinThic and bloodPress.


#### Create a shadow matrix of the NA values and explore NA cor

```{r warning=FALSE}
pS <- p

for(i in c(1:ncol(pS))) 
{
    pS[,i] <- as.numeric(as.character(pS[,i]))
}

pShadow <- as.data.frame(abs(is.na(pS)))

y <- pShadow[which(apply(pShadow, 2, sum) > 0)]

pShadow.cor <- cor(y)
```

r = 0.66 for NA cor of serumInsul and skinThick

r = 0.34 for NA cor of bmi and bloodPres

r = 0.31 for NA cor of skinThick and bloodPres

r = 0.22 for NA cor of serumInsul and bloodPres 

All other r values < 0.15

```{r warning=FALSE}
yy <- cor(pS, pShadow, use="pairwise.complete.obs")
```

Highest r values are 0.22 and 0.21 for age & skinThick and age & serumInsul.

Thus, it is most likely that the missing values are missing at random or missing at complete random.

Unable to revisit research team and investigate cause/rationale for missing data. Must address using imputed methods, will use MICE and VIM.

```{r warning=FALSE}
pImp <- mice(p, seed=123)
```

Address serumInsul as it is the largest contributor to NA values.
  Age and glucConc are have biggest cor to serumInsul, other parameters have some but lower cor.

```{r warning=FALSE}
pFit <- with(pImp, lm(serumInsul ~ age + glucConc + bmi + skinThick + bloodPres))

pPool <- pool(pFit)

summary(pPool)

pI <- complete(pImp, action=3)
```

Convert data.frame to numeric format for analysis 

```{r warning=FALSE}
for(i in c(1:ncol(pI))) 
{
    pI[,i] <- as.numeric(as.character(pI[,i]))
}
```

Convert classVar values to meaningful factors

```{r warning=FALSE}
pI$classVar <- factor(pI$classVar)

levels(pI$classVar) <- c("negative", "positive")

table(pI$classVar)
```

500=negative, 268=positive


### Building the Training and Test (hold-out) data sets with CARET

Define an 70%/30% train/test split of the data set

```{r warning=FALSE}
set.seed(123)

pItemp <- createDataPartition(pI[,ncol(pI)], p = 0.7, list = FALSE)

pItrain <- pI[pItemp,]
pItest <- pI[-pItemp,]
```

Count of total values in each dataset

```{r warning=FALSE}
pItrainN <- nrow(pItrain)*ncol(pItrain)
pItestN <- nrow(pItest)*ncol(pItest)
```

### Establish 10-fold cross-validation parameter for training and tuning models

Minimize overfitting of the training data.

```{r warning=FALSE}
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
```

### Optimize classification models with CARET

#### Build a generalized linear model (GLM) for dichotomous response data

```{r warning=FALSE}
set.seed(123)

ptm <- proc.time()

pI1fit <- train(classVar ~., data=pItrain, metric="Accuracy", trControl=fitControl, method="glm", tuneLength=10, na.action=na.omit)

pI1fitT <- proc.time() - ptm
```
```{r}
print(pI1fitT)
```

List the predictor column names and summarize the model

```{r warning=FALSE}
predictors(pI1fit)
print(pI1fit)
print(pI1fit$bestTune)
```
```{r echo=FALSE}
pI1fitImpt <- varImp(pI1fit)

ggplot(pI1fitImpt) +
	labs(title=pI1fit$method)
```

#### Build a c5.0 classification model

```{r warning=FALSE}
set.seed(123)

ptm <- proc.time()

pI2fit <- train(classVar ~., data=pItrain, metric="Accuracy", trControl=fitControl, method="C5.0", na.action=na.omit)

pI2fitT <- proc.time() - ptm
```
```{r warning=FALSE}
print(pI2fitT)
```

List the predictor column names and summarize the model

```{r warning=FALSE}
predictors(pI2fit)
print(pI2fit)
print(pI2fit$bestTune)
```
```{r echo=FALSE}
pI2fitImpt <- varImp(pI2fit)

ggplot(pI2fitImpt) +
	labs(title=pI2fit$method)
```

#### Build a RandomForest (RF) classification model

Optimize the mtry RF parameter.  

Default mtry in RF is sqrt(ncol(training)).  Bracket mtry parameters, start with grid min = sMt/2 and grid max = 2*sMt

```{r warning=FALSE}
sMt <- round(sqrt(ncol(pItrain)), digits=0)

rfGrid3 <- expand.grid(.mtry = c(sMt/2, sMt, sMt*2))

set.seed(123)

ptm <- proc.time()

pI3fit <- train(classVar ~., data=pItrain, method="rf", metric="Accuracy", trControl=fitControl, ntree=500, tuneGrid=rfGrid3, importance=TRUE, 
na.action=na.omit)

pI3fitT <- proc.time() - ptm
```
```{r}
print(pI3fitT)

predictors(pI3fit)
summary(pI3fit)
print(pI3fit)
print(pI3fit$bestTune)
```
```{r echo=FALSE}
pI3fitImpt <- varImp(pI3fit)

ggplot(pI3fitImpt) +
	labs(title=pI3fit$method)
```

### Save the optimized classification model parameters to txt or csv files

```{r eval=FALSE}
sink(file="~/Desktop/PimaIndianDiabetesData/output/pI_GLM_Model_Summary.txt")
summary(pI1fit)
sink()

sink(file="~/Desktop/PimaIndianDiabetesData/output/pI_c50_Model_Summary.txt")
summary(pI2fit)
sink()

write.csv(summary(pI3fit), file="~/Desktop/PimaIndianDiabetesData/output/pI_RF_Model_Summary.csv")
```

### Applying the optimized classification models to the Training data

```{r warning=FALSE}
pI1pred <- data.frame(predict(pI1fit, pItrain, interval = "predict", level =0.95))
pI2pred <- data.frame(predict(pI2fit, pItrain, interval = "predict", level =0.95))
pI3pred <- data.frame(predict(pI3fit, pItrain, interval = "predict", level =0.95))
```

### General functions for stats

```{r warning=FALSE}
# rounds numbers if numeric
round_numeric <- function(lst, decimals=2) {
    lapply(lst, function(x) {
        if (is.numeric(x)) {
            x <- round(x, decimals)
        }
        x
        })
}

# summary of model stats using a Confusion Matrix as input
# designed for explicit use with the confusionMatrix() function and binomial distribution

sumMod1 <- function(cm) {
    sumM <- list(acc=cm$overall["Accuracy"], # accuracy (TN+TP)/(TP+FP+TN+FN)
                 pre=cm$byClass["Precision"], # precision TP/(TP+FP)
                 rec=cm$byClass["Recall"], # recall TP/(TP+FN)
                 sens=cm$byClass["Sensitivity"],  # sensitivity = recall
                 spec=cm$byClass["Specificity"])  # specificity TN/(TN+FP)
    round_numeric(sumM)
}
```

### Combine all training data model stats into a single data frame

```{r warning=FALSE}
pICmat1 <- confusionMatrix(pI1pred[,1], pItrain[,ncol(pItrain)])
pICmat2 <- confusionMatrix(pI2pred[,1], pItrain[,ncol(pItrain)])
pICmat3 <- confusionMatrix(pI3pred[,1], pItrain[,ncol(pItrain)])
```

Summary of TRAINING results and metrics

```{r warning=FALSE}
ModelName <- c("glm TRAIN", "c5.0 TRAIN", "RF TRAIN")

pIModelComp <- as.data.frame(
    rbind(sumMod1(pICmat1),
          sumMod1(pICmat2),
          sumMod1(pICmat3)))

pIModelComp <- data.frame(cbind(ModelName, pIModelComp))
pIModelComp <- pIModelComp[order(pIModelComp$ModelName),]
rownames(pIModelComp) <- NULL

print(pIModelComp)
```

### Apply the optimized models to the Test (hold-out) data

```{r warning=FALSE}
pI1predTest <- data.frame(predict(pI1fit, pItest, interval = "predict", level =0.95))
pI2predTest <- data.frame(predict(pI2fit, pItest, interval = "predict", level =0.95))
pI3predTest <- data.frame(predict(pI3fit, pItest, interval = "predict", level =0.95))
```

### Measure the model performance on the Training and Test (hold-out) data

```{r warning=FALSE}
# combine all model stats into a single data frame

pICmat1T <- confusionMatrix(pI1predTest[,1], pItest[,ncol(pItest)])
pICmat2T <- confusionMatrix(pI2predTest[,1], pItest[,ncol(pItest)])
pICmat3T <- confusionMatrix(pI3predTest[,1], pItest[,ncol(pItest)])

pIModelCompT <- as.data.frame(
    rbind(sumMod1(pICmat1T),
          sumMod1(pICmat2T),
          sumMod1(pICmat3T)))

ModelNameT <- c("glm TEST", "c5.0 TEST", "RF TEST")
pIModelCompT <- data.frame(cbind(ModelNameT, pIModelCompT))
pIModelCompT <- pIModelCompT[order(pIModelCompT$ModelNameT),]
names(pIModelCompT)[names(pIModelCompT)=="ModelNameT"] <- "ModelName"
rownames(pIModelCompT) <- NULL

print(pIModelCompT)

# merge the training and testing datasets into one table

pIAllStats <- data.frame(rbind(pIModelComp, pIModelCompT))
pIAllStats <- pIAllStats[order(pIAllStats$ModelName),]
row.names(pIAllStats) <- NULL 

print(pIAllStats)
```

Write a CSV output file for any downstream use

```{r eval=FALSE}
pIAllStatsS <- pIAllStats
pIAllStatsS <- as.matrix(pIAllStatsS)

write.csv(pIAllStatsS, file="~/Desktop/PimaIndianDiabetesData/output/pIModelsAllStats.csv")
```

### GLM (generalized linear model) is the optimal model on Training and Test (hold-out) data

#### GLM model metrics


#####79% accuracy on training data
#####75% accuracy on test (hold-out) data
- these values are in-line with the accuracy values found by <A HREF="https://www.kaggle.com/forums/f/15/kaggle-forum/t/19387/what-is-the-highest-accuracy-achievable-for-pima-indian-diabetes-dataset">others</A> with the same data set.  Not clear if the few accuracy values >79% reported by others are on hold-out or training data, also not clear if others used 10-fold cross-validation (it *was* used with these GLM model results).


#####81% precision on training data
#####77% precision on test (hold-out) data
- precision is a measure of how many selected items are relevant


#####88% recall on training data
#####88% recall on test (hold-out) data
- recall is a measure of how many relevant items were selected


#### GLM model coefficients

Parameter    | Estimate | Std. Error | z-value | Pr(>|z|)
------------ | -------- | ---------- | ------- | --------
(Intercept)  | -9.70080 | 0.98962    | -9.803  | < 2e-16  ^a^
timesPreg    |  0.13573 | 0.03964    |  3.424  | 0.000618 ^a^
glucConc     |  0.03732 | 0.00484    | 7.714   | 1.22e-14 ^a^
bloodPres    | -0.00387 | 0.01000    | -0.387  | 0.698954    
skinThick    |  0.00831 | 0.01486    | 0.559   | 0.575965    
serumInsul   | -0.00203 | 0.00126    | -1.609  | 0.107512    
bmi          |  0.09999 | 0.02403    | 4.161   | 3.17e-05 ^a^
pedigreeFunc |  1.12988 | 0.36319    | 3.111   | 0.001865 ^b^ 
age          |  0.00903 | 0.01124    | 0.803   | 0.421745    

signif. codes:  a < 0.001, b < 0.01, c < 0.05


#### Important GLM model variables

```{r echo=FALSE}
pI1fitImpt <- varImp(pI1fit)

ggplot(pI1fitImpt) +
	labs(title=pI1fit$method)
```